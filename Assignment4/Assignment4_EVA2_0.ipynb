{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Assignment4_EVA2.0.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "aNyZv-Ec52ot"
      },
      "source": [
        "Assignment 4\n",
        "============\n",
        "\n",
        "Name : Nihar Kanungo\n",
        "Batch : 6:30 AM , Monday\n",
        "\n",
        "\n",
        "**Background :**\n",
        "- - - - - - - -\n",
        "This is a simple Image Recognition program which makes use of the MNIST preprocessed dataset to process the handwritten digit images and predict the numerical digit each image resents . The Code uses one of the most popular Tensorflow API Keras to perform the operations .It's a supervised Computer Vision problem.\n",
        "\n",
        "There are 4 different networks defined in this file . Each network defined in this file is an improvement over it's Predecessor. \n",
        "\n",
        "Network -1 : This is the Basic Network which defines the template over which the improvements will be added .\n",
        "\n",
        "Network -2 : This Network adds an additional functionality called \" Batch Normalization \" on top of Network-1\n",
        "\n",
        "Network -3 : This Network adds an additional functionality called \" Dropout \" on top of Network-2\n",
        "\n",
        "Network -4 : This Network adds variable learning rate to each epoch of the network -3 \n",
        "\n",
        "\n",
        "\n",
        "**Input**\n",
        "- - - -\n",
        "1) 60000 Handwritten digit images (between 0-9)\n",
        "\n",
        "2) The Images are already segreegated as Train and Test Data with the respective target values\n",
        "\n",
        "\n",
        "**Environment**\n",
        "- - - - - - - - \n",
        "\n",
        "    Development - Colab GPU , Jupyter Notebook\n",
        "    Repository : Github\n",
        "\n",
        "**Algorithm**\n",
        "- - - - - - \n",
        "    Linear Model \n",
        "    Convolutional Neural Network (2D) - Gray Scale images\n",
        "    Maxpooling \n",
        "    Softmax Activation function\n",
        "    loss Function : Categorical Crossentropy\n",
        "    Optimizer=Adam\n",
        "    Metrics=accuracy\n",
        "    Batch Normalization\n",
        "    Drop Out \n",
        "\n",
        "\n",
        "**Parameters**\n",
        "- - - - - - ---------------------\n",
        "\n",
        "    Batch Size - Variable \n",
        "    Epochs - Variable\n",
        "    Kernel Size - Variable (Advisable to use 3 * 3)\n",
        "    Number of Kernels - Variable \n",
        "    Learning Rate\n",
        "\n",
        "**Conditions**\n",
        "- - - - - -\n",
        "\n",
        "1. The Number of parameters < 15,000\n",
        "2. Should use only Conv2D\n",
        "3. Should not have applied Maxpooling before 2-4 layers of the conversion into number of classes (10 in this case)\n",
        "4. Maxpooling should be applied on receptive field of at least 5 x 5 or 7 x 7\n",
        "5. Activation function should be relu on conv 2D\n",
        "6. With < 15 EPochs\n",
        "\n",
        "**Expected Result**\n",
        "\n",
        "- - - - - - - - -\n",
        "To get >= 99.4 % accuracy \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "A_JGIXQ8EAO_"
      },
      "source": [
        "# **Import Libraries and modules**\n",
        "\n",
        "Import Libraries (Keras, Numpy) and \n",
        "       modules (Keras - Sequential, Dense, Dropout,Activation , Flatten) and\n",
        "       Dataset (mnist)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3m3w1Cw49Zkt",
        "colab": {}
      },
      "source": [
        "# https://keras.io/\n",
        "!pip install -q keras\n",
        "import keras"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Eso6UHE080D4",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten, Add\n",
        "from keras.layers import Convolution2D, MaxPooling2D\n",
        "from keras.utils import np_utils\n",
        "\n",
        "from keras.datasets import mnist"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "zByEi95J86RD"
      },
      "source": [
        "### Load pre-shuffled MNIST data into train and test sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7eRM0QWN83PV",
        "colab": {}
      },
      "source": [
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "1hzKCdZmEAPM"
      },
      "source": [
        "1. Print the shape of the Training Dataset (Number of Images, Size of the images)\n",
        "2. Import one of the popular library to plot charts/graphs and command to display it inline\n",
        "3. Code to show the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "4a4Be72j8-ZC",
        "outputId": "a4d9ab54-96fa-4476-e2e7-cd99d9cd86e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 303
        }
      },
      "source": [
        "print (X_train.shape)\n",
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline\n",
        "plt.imshow(X_train[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 28, 28)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f7c363ac860>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "WDO4QtQTEAPR"
      },
      "source": [
        "Reshape the Training and test data to gray scale"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "dkmprriw9AnZ",
        "colab": {}
      },
      "source": [
        "X_train = X_train.reshape(X_train.shape[0], 28, 28,1)\n",
        "X_test = X_test.reshape(X_test.shape[0], 28, 28,1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "PGJ9Z5rLEAPV"
      },
      "source": [
        "1. Convert the Images into float32 format\n",
        "2. Divide the values by 255 to make it with in 0-1 (Standardize)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "X2m4YS4E9CRh",
        "colab": {}
      },
      "source": [
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "X_train /= 255\n",
        "X_test /= 255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "VbVojYwVEAPa"
      },
      "source": [
        "Display the first 10 values of the target variable (Train)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0Mn0vAYD9DvB",
        "outputId": "d472d32e-a515-4484-919a-b8a4683ec59b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y_train[:10]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5, 0, 4, 1, 9, 2, 1, 3, 1, 4], dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ZG8JiXR39FHC",
        "colab": {}
      },
      "source": [
        "# Convert 1-dimensional class arrays to 10-dimensional class matrices\n",
        "Y_train = np_utils.to_categorical(y_train, 10)\n",
        "Y_test = np_utils.to_categorical(y_test, 10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "h8oFXu0CEAPh"
      },
      "source": [
        "Display the Target variable after it's one hot encoded"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "fYlFRvKS9HMB",
        "outputId": "5a01730c-8487-47ea-b48c-e6ddbfe90eb6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "Y_train[:10]\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
              "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "AV85Am_ZEAPm"
      },
      "source": [
        "***The Core Setup***\n",
        "=====================\n",
        "This core setup is going to be the basic framework . All the future codes will be improvements over this code but the basic setup will be unaltered . This would help us to understand the impact of each feature on our network. The Core setup is described below.\n",
        "\n",
        "1. Import the Activation layer \n",
        "2. Declare the Sequential model\n",
        "3. Add multiple convolution layers to increase the receptive field ( 3 x 3 kernels)\n",
        "4. Add Maxpooling to reduce the image size and increase the receptive field \n",
        "5. Add a large kernel of size 5 x 5 at this stage as going below this may not show significant details of the images\n",
        "6. Flatten the data to make it 1D \n",
        "7. Apply Softmax on each output to find out the predicted class\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "osKqT73Q9JJB",
        "outputId": "390d9d83-7d2b-4a3b-cbec-48ea9a168215",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275
        }
      },
      "source": [
        "from keras.layers import Activation\n",
        "model = Sequential()\n",
        "\n",
        " \n",
        "model.add(Convolution2D(8, 3, 3, activation='relu', input_shape=(28,28,1)))\n",
        "model.add(Convolution2D(16, 3, 3, activation='relu'))\n",
        "model.add(Convolution2D(24, 3, 3, activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Convolution2D(8, 1, 1, activation='relu'))\n",
        "model.add(Convolution2D(16, 3, 3, activation='relu'))\n",
        "model.add(Convolution2D(16, 3, 3, activation='relu'))\n",
        "model.add(Convolution2D(24, 3, 3, activation='relu'))\n",
        "model.add(Convolution2D(10, 1, activation='relu'))\n",
        "model.add(Convolution2D(10, 5))\n",
        "model.add(Flatten())\n",
        "model.add(Activation('softmax'))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(8, (3, 3), activation=\"relu\", input_shape=(28, 28, 1...)`\n",
            "  \"\"\"\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), activation=\"relu\")`\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(24, (3, 3), activation=\"relu\")`\n",
            "  import sys\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(8, (1, 1), activation=\"relu\")`\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), activation=\"relu\")`\n",
            "  # Remove the CWD from sys.path while we load stuff.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:11: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), activation=\"relu\")`\n",
            "  # This is added back by InteractiveShellApp.init_path()\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(24, (3, 3), activation=\"relu\")`\n",
            "  if sys.path[0] == '':\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "lnDRKPvFEAPq"
      },
      "source": [
        "Display the Summary of the Model. This would give the detail parameters each layer uses . This would be a great information to find out how the memory will be used and where are oppertunities for fine tuning.\n",
        "\n",
        " The Total parameters used for this network is < 15000"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "TzdAYg1k9K7Z",
        "outputId": "8fdebd01-b54d-4c3c-f0f0-2bb744f65281",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 544
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_19 (Conv2D)           (None, 26, 26, 8)         80        \n",
            "_________________________________________________________________\n",
            "conv2d_20 (Conv2D)           (None, 24, 24, 16)        1168      \n",
            "_________________________________________________________________\n",
            "conv2d_21 (Conv2D)           (None, 22, 22, 24)        3480      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 11, 11, 24)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_22 (Conv2D)           (None, 11, 11, 8)         200       \n",
            "_________________________________________________________________\n",
            "conv2d_23 (Conv2D)           (None, 9, 9, 16)          1168      \n",
            "_________________________________________________________________\n",
            "conv2d_24 (Conv2D)           (None, 7, 7, 16)          2320      \n",
            "_________________________________________________________________\n",
            "conv2d_25 (Conv2D)           (None, 5, 5, 24)          3480      \n",
            "_________________________________________________________________\n",
            "conv2d_26 (Conv2D)           (None, 5, 5, 10)          250       \n",
            "_________________________________________________________________\n",
            "conv2d_27 (Conv2D)           (None, 1, 1, 10)          2510      \n",
            "_________________________________________________________________\n",
            "flatten_3 (Flatten)          (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 14,656\n",
            "Trainable params: 14,656\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "4C3PGXWMEAPv"
      },
      "source": [
        "Compile the Model with the following parameters before it can be trained \n",
        "------------------------------------------------------------------------------------------------\n",
        "loss Function : Categorical Crossentropy\n",
        "\n",
        "Optimizer=Adam ( SGD is the best optimizer , however we will see the usage of it in later stages)\n",
        "\n",
        "Metrics=accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Zp6SuGrL9M3h",
        "outputId": "d85d6492-ad38-46a5-dd1a-a7ffcd190cc8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "model.compile(loss='categorical_crossentropy',\n",
        "             optimizer='adam',\n",
        "             metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0810 15:53:52.581322 140172777031552 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "W0810 15:53:52.616950 140172777031552 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "mQbYOdyTEAPz"
      },
      "source": [
        "The Training Phase of the network\n",
        "-------------------------------------------\n",
        "\n",
        "1. Fit the Model with training data \n",
        "2. Compare the output with target variable and find out the accuracy\n",
        "3. Calculate the Validation accuracy at each epoch and adjust the weights from validation results \n",
        "4. Run the Model with batch size of 32 ( Higher batch size increases the speed of training , however we will use 32 for this usecase)\n",
        "5. Run the model for 15 cycles over the training sample \n",
        "6. Define verbose parameter for display lines\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "4xWoKhPY9Of5",
        "outputId": "01ec5291-0520-48db-9799-959ac8fa2794",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 700
        }
      },
      "source": [
        "model.fit(X_train, Y_train, batch_size=32, nb_epoch=15, verbose=1,validation_data=(X_test, Y_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n",
            "W0810 15:53:52.800885 140172777031552 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "W0810 15:53:52.934099 140172777031552 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/15\n",
            "60000/60000 [==============================] - 32s 529us/step - loss: 0.2238 - acc: 0.9296 - val_loss: 0.0747 - val_acc: 0.9765\n",
            "Epoch 2/15\n",
            "60000/60000 [==============================] - 26s 432us/step - loss: 0.0750 - acc: 0.9775 - val_loss: 0.0528 - val_acc: 0.9830\n",
            "Epoch 3/15\n",
            "60000/60000 [==============================] - 26s 439us/step - loss: 0.0566 - acc: 0.9824 - val_loss: 0.0479 - val_acc: 0.9845\n",
            "Epoch 4/15\n",
            "60000/60000 [==============================] - 26s 436us/step - loss: 0.0483 - acc: 0.9849 - val_loss: 0.0498 - val_acc: 0.9848\n",
            "Epoch 5/15\n",
            "60000/60000 [==============================] - 26s 435us/step - loss: 0.0408 - acc: 0.9871 - val_loss: 0.0371 - val_acc: 0.9882\n",
            "Epoch 6/15\n",
            "60000/60000 [==============================] - 26s 431us/step - loss: 0.0357 - acc: 0.9883 - val_loss: 0.0358 - val_acc: 0.9873\n",
            "Epoch 7/15\n",
            "60000/60000 [==============================] - 26s 433us/step - loss: 0.0326 - acc: 0.9895 - val_loss: 0.0332 - val_acc: 0.9898\n",
            "Epoch 8/15\n",
            "60000/60000 [==============================] - 25s 424us/step - loss: 0.0279 - acc: 0.9911 - val_loss: 0.0305 - val_acc: 0.9904\n",
            "Epoch 9/15\n",
            "60000/60000 [==============================] - 25s 417us/step - loss: 0.0268 - acc: 0.9908 - val_loss: 0.0335 - val_acc: 0.9907\n",
            "Epoch 10/15\n",
            "60000/60000 [==============================] - 25s 423us/step - loss: 0.0235 - acc: 0.9921 - val_loss: 0.0377 - val_acc: 0.9895\n",
            "Epoch 11/15\n",
            "60000/60000 [==============================] - 26s 431us/step - loss: 0.0214 - acc: 0.9929 - val_loss: 0.0380 - val_acc: 0.9894\n",
            "Epoch 12/15\n",
            "60000/60000 [==============================] - 26s 437us/step - loss: 0.0212 - acc: 0.9932 - val_loss: 0.0433 - val_acc: 0.9854\n",
            "Epoch 13/15\n",
            "60000/60000 [==============================] - 26s 434us/step - loss: 0.0187 - acc: 0.9935 - val_loss: 0.0334 - val_acc: 0.9910\n",
            "Epoch 14/15\n",
            "60000/60000 [==============================] - 26s 433us/step - loss: 0.0183 - acc: 0.9937 - val_loss: 0.0366 - val_acc: 0.9902\n",
            "Epoch 15/15\n",
            "60000/60000 [==============================] - 26s 433us/step - loss: 0.0166 - acc: 0.9947 - val_loss: 0.0438 - val_acc: 0.9887\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f7c39ad8b70>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "EV8Y3X89EAP3"
      },
      "source": [
        "Print the Test Score of the last epoch "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "AtsH-lLk-eLb",
        "outputId": "5697426d-1acf-468c-ac41-b6aeba28d07e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "score = model.evaluate(X_test, Y_test, verbose=0)\n",
        "print(score)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.04376501578187672, 0.9887]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ZG3DeYIaEAQB"
      },
      "source": [
        "Define a variable to store the predicted test values \n",
        "\n",
        "Print the Predicted value and actual value for the first 9 test sample. This is basically to visualize how it looks\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "OCWoJkwE9suh",
        "outputId": "967633f5-2ff7-42ed-83b0-34238ca615b6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        }
      },
      "source": [
        "y_pred = model.predict(X_test)\n",
        "print(y_pred[:9])\n",
        "print(y_test[:9])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1.79540546e-13 1.02655150e-11 3.23662057e-08 1.02171605e-09\n",
            "  4.82984052e-12 2.44637470e-12 1.71174612e-22 1.00000000e+00\n",
            "  5.77865811e-11 2.74899108e-08]\n",
            " [1.37080708e-10 3.56518868e-08 9.99999881e-01 4.45560637e-08\n",
            "  7.97050248e-09 3.89434361e-12 6.72055052e-08 1.75540277e-11\n",
            "  2.34534347e-08 6.70795410e-14]\n",
            " [1.40696794e-11 9.99985218e-01 1.06105325e-07 5.79933379e-10\n",
            "  1.03231162e-06 2.79675200e-10 5.24114308e-09 1.35058890e-05\n",
            "  7.02166005e-08 1.15986065e-09]\n",
            " [9.99944210e-01 7.09811929e-13 8.74305712e-08 3.52322928e-11\n",
            "  1.15180248e-08 1.76408705e-07 1.40780157e-05 2.37323778e-08\n",
            "  9.55940216e-09 4.13616544e-05]\n",
            " [1.32241034e-17 1.90357526e-15 3.53359334e-12 8.34698495e-19\n",
            "  1.00000000e+00 3.35803532e-17 7.48222087e-18 1.33848799e-14\n",
            "  2.53393951e-15 1.90337524e-12]\n",
            " [3.99819636e-13 9.99995232e-01 2.13793044e-07 3.10637301e-12\n",
            "  2.02615979e-06 6.94282618e-11 9.69201941e-10 2.44782200e-06\n",
            "  5.44638279e-10 5.82795645e-10]\n",
            " [2.86096032e-17 5.31376315e-07 3.34267058e-10 1.43203435e-15\n",
            "  9.99999523e-01 2.23984670e-15 2.58367664e-17 4.65108257e-10\n",
            "  2.47774024e-10 1.90821536e-09]\n",
            " [1.58005831e-10 4.80743279e-10 3.43526843e-08 4.45892532e-08\n",
            "  2.41604666e-05 2.74365011e-08 1.24914537e-13 7.55200347e-08\n",
            "  1.69359846e-05 9.99958754e-01]\n",
            " [1.69689738e-05 2.11119405e-15 2.92874233e-07 6.26333296e-09\n",
            "  1.70859487e-08 9.98357475e-01 1.43044485e-06 2.60427310e-15\n",
            "  1.60342641e-03 2.04132448e-05]]\n",
            "[7 2 1 0 4 1 4 9 5]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c1UrVd3DvdK6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from IPython.display import Image"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3l1DYeBEvdK_",
        "colab_type": "text"
      },
      "source": [
        "Observations\n",
        "--------------\n",
        "Let's now analyze the outcome of the basic network . \n",
        "\n",
        "\n",
        "![img1](https://github.com/nkanungo/theschoolofai/blob/master/Assignment4/N1-Loss.png)\n",
        "1. The Loss curve shows that the training loss is constantly decreasing in every iteration . However the validation loss increased after 8th iteration . This gives an indication of overfitting . Now let's analyze the accuracy curve to see if our assumption is correct "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g71CzUcvvdLA",
        "colab_type": "text"
      },
      "source": [
        "![image.png](attachment:image.png)\n",
        "\n",
        "2. The accuracy curve shows a higher accuracy for training data , but the validation accuracy is not much as compared to the training data . Even though we attain validation accuracy of over 99.15% in one of the epochs but the difference between the training and validation accuracy is more than normal. this confirms our assumption to a greater extent . \n",
        "\n",
        "So we can conclude that the model is overfitting and hence it's not great for generalization. So we should think of some other way to make it a better fit . One thing that we can try adding is Batch Normalization . The reasons for considering Batch normalization as the first change to our network are"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eStt8lXgvdLC",
        "colab_type": "text"
      },
      "source": [
        "![image.png](attachment:image.png)\n",
        "\n",
        "BN reduces Covariate Shift. That is the change in distribution of activation of a component. By using BN, each neuron's activation becomes (more or less) a gaussian distribution, i.e. its usually not active, sometimes a bit active, rare very active."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y-XeLTHkvdLE",
        "colab_type": "text"
      },
      "source": [
        "![image.png](attachment:image.png)\n",
        "\n",
        "BN reduces effects of exploding and vanishing gradients, because every becomes roughly normal distributed. Without BN, low activations of one layer can lead to lower activations in the next layer, and then even lower ones in the next layer ...."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "QP-nnY5F_anO",
        "outputId": "952fe4ef-6d8c-4bec-ef5f-3afb296f7f55",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# from keras.layers import Activation\n",
        "from keras.layers import BatchNormalization\n",
        "model = Sequential()\n",
        "\n",
        " \n",
        "model.add(Convolution2D(8, 3, 3, activation='relu', input_shape=(28,28,1)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Convolution2D(14, 3, 3, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Convolution2D(24, 3, 3, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Convolution2D(8, 1, 1, activation='relu'))\n",
        "#model.add(BatchNormalization())\n",
        "model.add(Convolution2D(16, 3, 3, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Convolution2D(16, 3, 3, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Convolution2D(24, 3, 3, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Convolution2D(10, 1, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Convolution2D(10, 5))\n",
        "model.add(Flatten())\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "\n",
        "model.summary()\n",
        "\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "             optimizer='adam',\n",
        "             metrics=['accuracy'])\n",
        "\n",
        "model.fit(X_train, Y_train, batch_size=32, nb_epoch=15, verbose=1,validation_data=(X_test, Y_test))\n",
        "\n",
        "score = model.evaluate(X_test, Y_test, verbose=0)\n",
        "print(score)\n",
        "\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "print(y_pred[:9])\n",
        "print(y_test[:9])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(8, (3, 3), activation=\"relu\", input_shape=(28, 28, 1...)`\n",
            "  \"\"\"\n",
            "W0810 16:00:29.933172 140172777031552 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(14, (3, 3), activation=\"relu\")`\n",
            "  import sys\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(24, (3, 3), activation=\"relu\")`\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(8, (1, 1), activation=\"relu\")`\n",
            "  if sys.path[0] == '':\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:14: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), activation=\"relu\")`\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:16: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), activation=\"relu\")`\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:18: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(24, (3, 3), activation=\"relu\")`\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_28 (Conv2D)           (None, 26, 26, 8)         80        \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 26, 26, 8)         32        \n",
            "_________________________________________________________________\n",
            "conv2d_29 (Conv2D)           (None, 24, 24, 14)        1022      \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 24, 24, 14)        56        \n",
            "_________________________________________________________________\n",
            "conv2d_30 (Conv2D)           (None, 22, 22, 24)        3048      \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 22, 22, 24)        96        \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 11, 11, 24)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_31 (Conv2D)           (None, 11, 11, 8)         200       \n",
            "_________________________________________________________________\n",
            "conv2d_32 (Conv2D)           (None, 9, 9, 16)          1168      \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 9, 9, 16)          64        \n",
            "_________________________________________________________________\n",
            "conv2d_33 (Conv2D)           (None, 7, 7, 16)          2320      \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 7, 7, 16)          64        \n",
            "_________________________________________________________________\n",
            "conv2d_34 (Conv2D)           (None, 5, 5, 24)          3480      \n",
            "_________________________________________________________________\n",
            "batch_normalization_6 (Batch (None, 5, 5, 24)          96        \n",
            "_________________________________________________________________\n",
            "conv2d_35 (Conv2D)           (None, 5, 5, 10)          250       \n",
            "_________________________________________________________________\n",
            "batch_normalization_7 (Batch (None, 5, 5, 10)          40        \n",
            "_________________________________________________________________\n",
            "conv2d_36 (Conv2D)           (None, 1, 1, 10)          2510      \n",
            "_________________________________________________________________\n",
            "flatten_4 (Flatten)          (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 14,526\n",
            "Trainable params: 14,302\n",
            "Non-trainable params: 224\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:34: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/15\n",
            "60000/60000 [==============================] - 44s 740us/step - loss: 0.1910 - acc: 0.9417 - val_loss: 0.0507 - val_acc: 0.9828\n",
            "Epoch 2/15\n",
            "60000/60000 [==============================] - 42s 703us/step - loss: 0.0535 - acc: 0.9832 - val_loss: 0.0456 - val_acc: 0.9841\n",
            "Epoch 3/15\n",
            "60000/60000 [==============================] - 42s 699us/step - loss: 0.0420 - acc: 0.9867 - val_loss: 0.0341 - val_acc: 0.9892\n",
            "Epoch 4/15\n",
            "60000/60000 [==============================] - 42s 699us/step - loss: 0.0350 - acc: 0.9885 - val_loss: 0.0365 - val_acc: 0.9886\n",
            "Epoch 5/15\n",
            "60000/60000 [==============================] - 42s 696us/step - loss: 0.0301 - acc: 0.9901 - val_loss: 0.0444 - val_acc: 0.9851\n",
            "Epoch 6/15\n",
            "60000/60000 [==============================] - 42s 699us/step - loss: 0.0271 - acc: 0.9910 - val_loss: 0.0349 - val_acc: 0.9893\n",
            "Epoch 7/15\n",
            "60000/60000 [==============================] - 42s 703us/step - loss: 0.0238 - acc: 0.9919 - val_loss: 0.0307 - val_acc: 0.9903\n",
            "Epoch 8/15\n",
            "60000/60000 [==============================] - 42s 700us/step - loss: 0.0212 - acc: 0.9931 - val_loss: 0.0335 - val_acc: 0.9893\n",
            "Epoch 9/15\n",
            "60000/60000 [==============================] - 43s 721us/step - loss: 0.0198 - acc: 0.9934 - val_loss: 0.0296 - val_acc: 0.9921\n",
            "Epoch 10/15\n",
            "60000/60000 [==============================] - 44s 731us/step - loss: 0.0192 - acc: 0.9935 - val_loss: 0.0329 - val_acc: 0.9893\n",
            "Epoch 11/15\n",
            "60000/60000 [==============================] - 44s 729us/step - loss: 0.0168 - acc: 0.9945 - val_loss: 0.0393 - val_acc: 0.9884\n",
            "Epoch 12/15\n",
            "60000/60000 [==============================] - 44s 737us/step - loss: 0.0157 - acc: 0.9950 - val_loss: 0.0353 - val_acc: 0.9888\n",
            "Epoch 13/15\n",
            "60000/60000 [==============================] - 44s 731us/step - loss: 0.0142 - acc: 0.9949 - val_loss: 0.0286 - val_acc: 0.9915\n",
            "Epoch 14/15\n",
            "60000/60000 [==============================] - 43s 721us/step - loss: 0.0135 - acc: 0.9954 - val_loss: 0.0345 - val_acc: 0.9894\n",
            "Epoch 15/15\n",
            "60000/60000 [==============================] - 43s 720us/step - loss: 0.0125 - acc: 0.9960 - val_loss: 0.0305 - val_acc: 0.9906\n",
            "[0.030539237535088432, 0.9906]\n",
            "[[1.28350390e-12 9.49495593e-09 1.70399239e-09 3.29053410e-06\n",
            "  1.36137475e-15 5.91821453e-11 5.11467445e-17 9.99996662e-01\n",
            "  1.08359651e-13 1.61185980e-08]\n",
            " [1.46695918e-08 7.82271172e-08 9.99999881e-01 6.13845974e-10\n",
            "  4.01116002e-10 1.13936334e-16 1.38726612e-08 6.42414455e-11\n",
            "  3.42936374e-10 1.42271944e-10]\n",
            " [1.28955709e-11 9.99999523e-01 2.92145613e-11 7.36270767e-10\n",
            "  7.04401373e-08 1.02758886e-08 2.65212226e-08 3.95297917e-07\n",
            "  2.10933021e-10 2.74201044e-11]\n",
            " [9.99998689e-01 1.07560610e-11 4.14718526e-09 1.60954194e-10\n",
            "  1.76544201e-09 3.22702953e-09 1.26609632e-06 8.54469134e-11\n",
            "  2.72786904e-09 5.43473000e-09]\n",
            " [6.88955593e-15 5.40501651e-14 5.79064291e-15 1.07214288e-14\n",
            "  9.99998689e-01 3.56213506e-14 5.13216379e-11 1.03955854e-11\n",
            "  4.52863476e-11 1.32191292e-06]\n",
            " [5.12714567e-12 9.99999404e-01 8.04253955e-11 4.88717096e-12\n",
            "  9.21771459e-09 2.19668641e-12 1.60529434e-09 6.02376304e-07\n",
            "  4.16192081e-12 4.92002749e-12]\n",
            " [1.28279525e-17 2.22733693e-10 4.07721105e-14 9.78095308e-16\n",
            "  1.00000000e+00 4.87692421e-11 1.88901325e-12 8.07019285e-10\n",
            "  4.32305650e-11 9.06343001e-09]\n",
            " [2.61352593e-08 2.35182533e-11 5.88387228e-10 1.07697788e-08\n",
            "  8.86143825e-05 1.24666462e-06 1.71225548e-10 1.41196978e-07\n",
            "  2.01252601e-06 9.99907970e-01]\n",
            " [3.51964241e-06 6.65490774e-08 1.05718755e-06 1.06512754e-08\n",
            "  2.39027709e-09 8.57220054e-01 1.42297953e-01 1.65544314e-10\n",
            "  4.77249472e-04 4.28630358e-08]]\n",
            "[7 2 1 0 4 1 4 9 5]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nC0GaqDuvdLI",
        "colab_type": "text"
      },
      "source": [
        "Observations\n",
        "------------------------\n",
        "Let's now analyze the effect of Batch Normalization to out network. In this case we have added a small percentage of batch normalization after every convolution step.\n",
        "\n",
        "\n",
        "![image.png](attachment:image.png)\n",
        "\n",
        "The Loss curve shows that the training loss and validation loss both decreases constantly , however the validation loss is more than the training loss . That means we haven't been able to reduce the effect of overfitting completely . The Model is still not generalizing well. Let's see how the accuracy stands and how close this is to our target ."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_A75QJKcvdLJ",
        "colab_type": "text"
      },
      "source": [
        "![image.png](attachment:image.png)\n",
        "\n",
        "The accuracy curve shows that on the 10th Epoch our accuracy was above 99.2% but still below the target . At the same time we can still see that the difference between the training and validation accuracy is still high . So our job is not yet over . We need to think of some other alternative /addition on how to generalize the network and get a high validation accuracy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nuJsIbdrvdLK",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "![image.png](attachment:image.png)\n",
        "\n",
        "\n",
        "\n",
        "One of the most trusted ways of reducing the overfitting is to drop out some of the training samples so that the network takes hard steps to find out other features to predict the class output . The drop out normally is considered as a fraction of the training samples. Here we will consider a small amount of drop out after every convolution steps . One of the logic behind drop out to help reduce overfitting somes from the fact that during training, for each image, feature detectors are deleted with probability q = 1  p = 0.5 and the remaining weights are trained by backpropagation. So this reduces the Dependency to improve generalization . Let's see how in helps us to generalize the effect of over fitting."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "FdDtE7dBE0nG",
        "outputId": "38197c4e-966c-4b63-aec6-eaeec6ed3e8b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# from keras.layers import Activation\n",
        "#from keras.layers import BatchNormalization\n",
        "model = Sequential()\n",
        "\n",
        " \n",
        "model.add(Convolution2D(8, 3, 3, activation='relu', input_shape=(28,28,1)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.1))\n",
        "model.add(Convolution2D(14, 3, 3, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.1))\n",
        "model.add(Convolution2D(24, 3, 3, activation='relu'))\n",
        "#model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Convolution2D(8, 1, 1, activation='relu'))\n",
        "#model.add(BatchNormalization())\n",
        "#model.add(Dropout(0.1))\n",
        "model.add(Convolution2D(16, 3, 3, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.1))\n",
        "model.add(Convolution2D(16, 3, 3, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.1))\n",
        "model.add(Convolution2D(24, 3, 3, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.1))\n",
        "model.add(Convolution2D(10, 1, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.1))\n",
        "model.add(Convolution2D(10, 5))\n",
        "model.add(Flatten())\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "\n",
        "model.summary()\n",
        "\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "             optimizer='adam',\n",
        "             metrics=['accuracy'])\n",
        "\n",
        "model.fit(X_train, Y_train, batch_size=32, nb_epoch=15, verbose=1,validation_data=(X_test, Y_test))\n",
        "\n",
        "score = model.evaluate(X_test, Y_test, verbose=0)\n",
        "print(score)\n",
        "\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "print(y_pred[:9])\n",
        "print(y_test[:9])\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(8, (3, 3), activation=\"relu\", input_shape=(28, 28, 1...)`\n",
            "  after removing the cwd from sys.path.\n",
            "W0810 16:11:19.561103 140172777031552 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(14, (3, 3), activation=\"relu\")`\n",
            "  import sys\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(24, (3, 3), activation=\"relu\")`\n",
            "  # Remove the CWD from sys.path while we load stuff.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(8, (1, 1), activation=\"relu\")`\n",
            "  del sys.path[0]\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:16: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), activation=\"relu\")`\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:19: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), activation=\"relu\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:22: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(24, (3, 3), activation=\"relu\")`\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_37 (Conv2D)           (None, 26, 26, 8)         80        \n",
            "_________________________________________________________________\n",
            "batch_normalization_8 (Batch (None, 26, 26, 8)         32        \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 26, 26, 8)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_38 (Conv2D)           (None, 24, 24, 14)        1022      \n",
            "_________________________________________________________________\n",
            "batch_normalization_9 (Batch (None, 24, 24, 14)        56        \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 24, 24, 14)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_39 (Conv2D)           (None, 22, 22, 24)        3048      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2 (None, 11, 11, 24)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_40 (Conv2D)           (None, 11, 11, 8)         200       \n",
            "_________________________________________________________________\n",
            "conv2d_41 (Conv2D)           (None, 9, 9, 16)          1168      \n",
            "_________________________________________________________________\n",
            "batch_normalization_10 (Batc (None, 9, 9, 16)          64        \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 9, 9, 16)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_42 (Conv2D)           (None, 7, 7, 16)          2320      \n",
            "_________________________________________________________________\n",
            "batch_normalization_11 (Batc (None, 7, 7, 16)          64        \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 7, 7, 16)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_43 (Conv2D)           (None, 5, 5, 24)          3480      \n",
            "_________________________________________________________________\n",
            "batch_normalization_12 (Batc (None, 5, 5, 24)          96        \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 5, 5, 24)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_44 (Conv2D)           (None, 5, 5, 10)          250       \n",
            "_________________________________________________________________\n",
            "batch_normalization_13 (Batc (None, 5, 5, 10)          40        \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 5, 5, 10)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_45 (Conv2D)           (None, 1, 1, 10)          2510      \n",
            "_________________________________________________________________\n",
            "flatten_5 (Flatten)          (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "activation_5 (Activation)    (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 14,430\n",
            "Trainable params: 14,254\n",
            "Non-trainable params: 176\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:40: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/15\n",
            "60000/60000 [==============================] - 47s 784us/step - loss: 0.2488 - acc: 0.9229 - val_loss: 0.0625 - val_acc: 0.9803\n",
            "Epoch 2/15\n",
            "60000/60000 [==============================] - 45s 745us/step - loss: 0.0802 - acc: 0.9755 - val_loss: 0.0449 - val_acc: 0.9866\n",
            "Epoch 3/15\n",
            "60000/60000 [==============================] - 45s 746us/step - loss: 0.0604 - acc: 0.9809 - val_loss: 0.0435 - val_acc: 0.9858\n",
            "Epoch 4/15\n",
            "60000/60000 [==============================] - 45s 749us/step - loss: 0.0533 - acc: 0.9836 - val_loss: 0.0326 - val_acc: 0.9894\n",
            "Epoch 5/15\n",
            "60000/60000 [==============================] - 45s 749us/step - loss: 0.0462 - acc: 0.9857 - val_loss: 0.0307 - val_acc: 0.9908\n",
            "Epoch 6/15\n",
            "60000/60000 [==============================] - 45s 749us/step - loss: 0.0426 - acc: 0.9869 - val_loss: 0.0400 - val_acc: 0.9879\n",
            "Epoch 7/15\n",
            "60000/60000 [==============================] - 45s 750us/step - loss: 0.0396 - acc: 0.9872 - val_loss: 0.0335 - val_acc: 0.9895\n",
            "Epoch 8/15\n",
            "60000/60000 [==============================] - 45s 745us/step - loss: 0.0388 - acc: 0.9880 - val_loss: 0.0248 - val_acc: 0.9926\n",
            "Epoch 9/15\n",
            "60000/60000 [==============================] - 44s 742us/step - loss: 0.0342 - acc: 0.9893 - val_loss: 0.0292 - val_acc: 0.9913\n",
            "Epoch 10/15\n",
            "60000/60000 [==============================] - 44s 739us/step - loss: 0.0337 - acc: 0.9893 - val_loss: 0.0276 - val_acc: 0.9910\n",
            "Epoch 11/15\n",
            "60000/60000 [==============================] - 45s 742us/step - loss: 0.0324 - acc: 0.9895 - val_loss: 0.0257 - val_acc: 0.9917\n",
            "Epoch 12/15\n",
            "60000/60000 [==============================] - 44s 725us/step - loss: 0.0322 - acc: 0.9892 - val_loss: 0.0246 - val_acc: 0.9922\n",
            "Epoch 13/15\n",
            "60000/60000 [==============================] - 43s 724us/step - loss: 0.0309 - acc: 0.9900 - val_loss: 0.0258 - val_acc: 0.9917\n",
            "Epoch 14/15\n",
            "60000/60000 [==============================] - 44s 726us/step - loss: 0.0286 - acc: 0.9908 - val_loss: 0.0273 - val_acc: 0.9918\n",
            "Epoch 15/15\n",
            "60000/60000 [==============================] - 45s 743us/step - loss: 0.0288 - acc: 0.9907 - val_loss: 0.0254 - val_acc: 0.9929\n",
            "[0.025382898516010027, 0.9929]\n",
            "[[1.03653497e-09 1.43840913e-08 4.63879559e-07 2.92465330e-07\n",
            "  2.86336395e-08 3.64442276e-09 7.58439925e-12 9.99999285e-01\n",
            "  1.51794272e-11 5.84290838e-09]\n",
            " [2.76935808e-08 3.23266831e-05 9.99967694e-01 3.77580811e-09\n",
            "  1.31879183e-08 9.54747132e-13 1.37369831e-08 7.06292316e-11\n",
            "  7.83650422e-10 2.20737820e-11]\n",
            " [2.26604091e-09 9.99992251e-01 1.59178697e-07 7.11705042e-08\n",
            "  7.87792942e-07 3.41110109e-08 1.85748391e-07 5.85303769e-06\n",
            "  4.22908286e-09 5.93155789e-07]\n",
            " [9.99964952e-01 3.61060848e-10 7.10410859e-08 3.24776006e-09\n",
            "  9.34023525e-09 6.46455334e-08 3.32327982e-05 8.92495869e-11\n",
            "  1.63727373e-06 3.21632889e-08]\n",
            " [8.25134627e-09 3.53070484e-09 1.01366290e-10 3.85979920e-12\n",
            "  9.99995112e-01 7.13340365e-09 1.05638236e-08 3.48074303e-09\n",
            "  2.06132444e-09 4.82742780e-06]\n",
            " [3.79125042e-09 9.99994040e-01 4.92895538e-07 2.77721601e-09\n",
            "  1.18330195e-06 1.57714897e-09 8.46945767e-08 3.84982513e-06\n",
            "  1.60759916e-09 3.54868064e-07]\n",
            " [5.91223875e-11 6.81126676e-06 4.90641057e-08 1.84779136e-09\n",
            "  9.99882817e-01 3.35634951e-07 7.93832777e-10 5.57138228e-05\n",
            "  2.06580025e-05 3.35417426e-05]\n",
            " [3.40644485e-10 1.77270601e-10 1.23323973e-08 1.49084116e-07\n",
            "  1.70999730e-04 1.42856823e-06 3.56372570e-10 5.61261082e-08\n",
            "  2.96387412e-07 9.99827087e-01]\n",
            " [2.63290843e-07 1.13948129e-09 1.12200915e-07 6.95879399e-09\n",
            "  3.00612868e-08 9.79100287e-01 1.22307548e-02 2.26792385e-09\n",
            "  8.66463594e-03 3.96082032e-06]]\n",
            "[7 2 1 0 4 1 4 9 5]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PtrvT3iUvdLQ",
        "colab_type": "text"
      },
      "source": [
        "Observations\n",
        "----------------------\n",
        "Did you observe the behaviour of the network ? Let's see pictorially how it behaved .\n",
        "\n",
        "![image.png](attachment:image.png)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dh_Ni8etvdLR",
        "colab_type": "text"
      },
      "source": [
        "![image.png](attachment:image.png)\n",
        "\n",
        "\n",
        "Both the Loss curve and Accuracy curve shows great improvements over the last network . The Validation loss is below the training loss and the validation accuracy is over the training accuracy . At the same time the difference between the training and validation accuracy is narrow . This looks like a great network. However we still could not achieve the magic number 99.4 . What could be the reason ? \n",
        "\n",
        "1. One reason i could think of is that the total number of iterations are little less . We may try to run it for 20-25 epochs and let the network do more optimization to it's weights . ( We will try this little later , for now let's focus to achieve with < 15 epochs)\n",
        "2. May be the random weights are little bad and running it for few more times may achieve the target \n",
        "\n",
        "However our job was to achieve the target with less than 15 epochs . So it's worth thinking if something else can help us here , something which is logically correct to be used at this stage .  Did you guess it ? "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "xmZhz8F5WGjO"
      },
      "source": [
        "Yes we are talking about how the weights are optimized and what's the rate of optimization ? This brings us to think about how the optimizer learns to change the weights . The most important factor is the learning rate here which is the default one we have taken so far . The Networks are very much sensitive towards the learning rate changes .\n",
        "\n",
        "![image.png](attachment:image.png)\n",
        "\n",
        "High Learning Rate - The algorithm may oscillate and become unstable\n",
        "Low Learning Rate -  The algorithm will take too long to converge\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m4zeH9dzvdLT",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "It is not practical to determine the optimal setting for the learning rate before training, and, in fact, the optimal learning rate changes during the training process, as the algorithm moves across the performance surface.The performance of the steepest descent algorithm can be improved if we allow the learning rate to change during the training process. \n",
        "\n",
        "![image.png](attachment:image.png)\n",
        "\n",
        "So let's add a scheduler to modify the learning rate everytime to change the fractions in the previous learning rate . This should hopefully generalize our model to a greater extent and help us achieve the target with very few training epochs and time .\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9iSYhmXnJwRX",
        "outputId": "c92830b6-aae2-4379-ccc9-cc288e1c1339",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# from keras.layers import Activation\n",
        "#from keras.layers import BatchNormalization\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import LearningRateScheduler\n",
        "model = Sequential()\n",
        "\n",
        " \n",
        "model.add(Convolution2D(8, 3, 3, activation='relu', input_shape=(28,28,1)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.1))\n",
        "model.add(Convolution2D(14, 3, 3, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.1))\n",
        "model.add(Convolution2D(24, 3, 3, activation='relu'))\n",
        "#model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Convolution2D(8, 1, 1, activation='relu'))\n",
        "#model.add(BatchNormalization())\n",
        "#model.add(Dropout(0.1))\n",
        "model.add(Convolution2D(16, 3, 3, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.1))\n",
        "model.add(Convolution2D(16, 3, 3, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.1))\n",
        "model.add(Convolution2D(24, 3, 3, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.1))\n",
        "model.add(Convolution2D(10, 1, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.1))\n",
        "model.add(Convolution2D(10, 5))\n",
        "model.add(Flatten())\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "\n",
        "model.summary()\n",
        "\n",
        "\n",
        "def scheduler(epoch, lr):\n",
        "    return round(0.003 * 1/(1 + 0.319 * epoch), 10)\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.003), metrics=['accuracy'])\n",
        "\n",
        "model.fit(X_train, Y_train, batch_size=32, epochs=15, verbose=1, validation_data=(X_test, Y_test), callbacks=[LearningRateScheduler(scheduler, verbose=1)])\n",
        "\n",
        "\n",
        "score = model.evaluate(X_test, Y_test, verbose=0)\n",
        "print(score)\n",
        "\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "print(y_pred[:9])\n",
        "print(y_test[:9])\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(8, (3, 3), activation=\"relu\", input_shape=(28, 28, 1...)`\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(14, (3, 3), activation=\"relu\")`\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(24, (3, 3), activation=\"relu\")`\n",
            "  if sys.path[0] == '':\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:15: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(8, (1, 1), activation=\"relu\")`\n",
            "  from ipykernel import kernelapp as app\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:18: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), activation=\"relu\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:21: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), activation=\"relu\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:24: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(24, (3, 3), activation=\"relu\")`\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_46 (Conv2D)           (None, 26, 26, 8)         80        \n",
            "_________________________________________________________________\n",
            "batch_normalization_14 (Batc (None, 26, 26, 8)         32        \n",
            "_________________________________________________________________\n",
            "dropout_7 (Dropout)          (None, 26, 26, 8)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_47 (Conv2D)           (None, 24, 24, 14)        1022      \n",
            "_________________________________________________________________\n",
            "batch_normalization_15 (Batc (None, 24, 24, 14)        56        \n",
            "_________________________________________________________________\n",
            "dropout_8 (Dropout)          (None, 24, 24, 14)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_48 (Conv2D)           (None, 22, 22, 24)        3048      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_6 (MaxPooling2 (None, 11, 11, 24)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_49 (Conv2D)           (None, 11, 11, 8)         200       \n",
            "_________________________________________________________________\n",
            "conv2d_50 (Conv2D)           (None, 9, 9, 16)          1168      \n",
            "_________________________________________________________________\n",
            "batch_normalization_16 (Batc (None, 9, 9, 16)          64        \n",
            "_________________________________________________________________\n",
            "dropout_9 (Dropout)          (None, 9, 9, 16)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_51 (Conv2D)           (None, 7, 7, 16)          2320      \n",
            "_________________________________________________________________\n",
            "batch_normalization_17 (Batc (None, 7, 7, 16)          64        \n",
            "_________________________________________________________________\n",
            "dropout_10 (Dropout)         (None, 7, 7, 16)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_52 (Conv2D)           (None, 5, 5, 24)          3480      \n",
            "_________________________________________________________________\n",
            "batch_normalization_18 (Batc (None, 5, 5, 24)          96        \n",
            "_________________________________________________________________\n",
            "dropout_11 (Dropout)         (None, 5, 5, 24)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_53 (Conv2D)           (None, 5, 5, 10)          250       \n",
            "_________________________________________________________________\n",
            "batch_normalization_19 (Batc (None, 5, 5, 10)          40        \n",
            "_________________________________________________________________\n",
            "dropout_12 (Dropout)         (None, 5, 5, 10)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_54 (Conv2D)           (None, 1, 1, 10)          2510      \n",
            "_________________________________________________________________\n",
            "flatten_6 (Flatten)          (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "activation_6 (Activation)    (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 14,430\n",
            "Trainable params: 14,254\n",
            "Non-trainable params: 176\n",
            "_________________________________________________________________\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/15\n",
            "\n",
            "Epoch 00001: LearningRateScheduler setting learning rate to 0.003.\n",
            "60000/60000 [==============================] - 49s 822us/step - loss: 0.1756 - acc: 0.9450 - val_loss: 0.0582 - val_acc: 0.9811\n",
            "Epoch 2/15\n",
            "\n",
            "Epoch 00002: LearningRateScheduler setting learning rate to 0.0022744503.\n",
            "60000/60000 [==============================] - 45s 743us/step - loss: 0.0699 - acc: 0.9787 - val_loss: 0.0441 - val_acc: 0.9868\n",
            "Epoch 3/15\n",
            "\n",
            "Epoch 00003: LearningRateScheduler setting learning rate to 0.0018315018.\n",
            "60000/60000 [==============================] - 46s 758us/step - loss: 0.0542 - acc: 0.9828 - val_loss: 0.0427 - val_acc: 0.9870\n",
            "Epoch 4/15\n",
            "\n",
            "Epoch 00004: LearningRateScheduler setting learning rate to 0.0015329586.\n",
            "60000/60000 [==============================] - 47s 780us/step - loss: 0.0437 - acc: 0.9863 - val_loss: 0.0368 - val_acc: 0.9885\n",
            "Epoch 5/15\n",
            "\n",
            "Epoch 00005: LearningRateScheduler setting learning rate to 0.0013181019.\n",
            "60000/60000 [==============================] - 46s 771us/step - loss: 0.0405 - acc: 0.9873 - val_loss: 0.0266 - val_acc: 0.9917\n",
            "Epoch 6/15\n",
            "\n",
            "Epoch 00006: LearningRateScheduler setting learning rate to 0.0011560694.\n",
            "60000/60000 [==============================] - 45s 757us/step - loss: 0.0342 - acc: 0.9892 - val_loss: 0.0236 - val_acc: 0.9927\n",
            "Epoch 7/15\n",
            "\n",
            "Epoch 00007: LearningRateScheduler setting learning rate to 0.0010295127.\n",
            "60000/60000 [==============================] - 45s 752us/step - loss: 0.0328 - acc: 0.9898 - val_loss: 0.0219 - val_acc: 0.9935\n",
            "Epoch 8/15\n",
            "\n",
            "Epoch 00008: LearningRateScheduler setting learning rate to 0.0009279307.\n",
            "60000/60000 [==============================] - 45s 753us/step - loss: 0.0294 - acc: 0.9904 - val_loss: 0.0236 - val_acc: 0.9932\n",
            "Epoch 9/15\n",
            "\n",
            "Epoch 00009: LearningRateScheduler setting learning rate to 0.0008445946.\n",
            "60000/60000 [==============================] - 45s 758us/step - loss: 0.0274 - acc: 0.9907 - val_loss: 0.0222 - val_acc: 0.9936\n",
            "Epoch 10/15\n",
            "\n",
            "Epoch 00010: LearningRateScheduler setting learning rate to 0.0007749935.\n",
            "60000/60000 [==============================] - 46s 761us/step - loss: 0.0250 - acc: 0.9918 - val_loss: 0.0215 - val_acc: 0.9931\n",
            "Epoch 11/15\n",
            "\n",
            "Epoch 00011: LearningRateScheduler setting learning rate to 0.0007159905.\n",
            "60000/60000 [==============================] - 44s 740us/step - loss: 0.0235 - acc: 0.9925 - val_loss: 0.0204 - val_acc: 0.9942\n",
            "Epoch 12/15\n",
            "\n",
            "Epoch 00012: LearningRateScheduler setting learning rate to 0.000665336.\n",
            "60000/60000 [==============================] - 45s 756us/step - loss: 0.0223 - acc: 0.9929 - val_loss: 0.0206 - val_acc: 0.9940\n",
            "Epoch 13/15\n",
            "\n",
            "Epoch 00013: LearningRateScheduler setting learning rate to 0.0006213753.\n",
            "60000/60000 [==============================] - 45s 744us/step - loss: 0.0225 - acc: 0.9927 - val_loss: 0.0197 - val_acc: 0.9939\n",
            "Epoch 14/15\n",
            "\n",
            "Epoch 00014: LearningRateScheduler setting learning rate to 0.0005828638.\n",
            "60000/60000 [==============================] - 43s 725us/step - loss: 0.0206 - acc: 0.9934 - val_loss: 0.0224 - val_acc: 0.9932\n",
            "Epoch 15/15\n",
            "\n",
            "Epoch 00015: LearningRateScheduler setting learning rate to 0.0005488474.\n",
            "60000/60000 [==============================] - 43s 722us/step - loss: 0.0200 - acc: 0.9934 - val_loss: 0.0197 - val_acc: 0.9944\n",
            "[0.019699536830261058, 0.9944]\n",
            "[[2.8027877e-11 5.1190536e-09 2.4967948e-08 4.3410014e-07 4.2260089e-13\n",
            "  1.0333157e-09 7.3869605e-13 9.9999952e-01 1.9454126e-10 2.2945944e-08]\n",
            " [5.5242577e-07 6.9776011e-06 9.9996781e-01 6.4672201e-09 2.4177302e-09\n",
            "  1.3357317e-10 2.4633759e-05 8.3142776e-10 2.2047635e-09 2.8514214e-11]\n",
            " [4.9306315e-08 9.9999309e-01 3.5309034e-07 4.2728372e-09 4.6426820e-08\n",
            "  5.3823057e-09 6.0063981e-06 4.0614373e-07 7.8631672e-08 1.6825128e-09]\n",
            " [9.9982208e-01 1.2798834e-10 9.3600150e-09 2.3039837e-08 3.6256502e-08\n",
            "  1.8793408e-07 1.5406149e-04 8.4925826e-09 9.0394371e-07 2.2721902e-05]\n",
            " [1.9738566e-12 1.5127498e-09 2.1918829e-10 7.1327569e-11 9.9999893e-01\n",
            "  1.7820408e-12 1.2660610e-09 1.2287408e-09 4.7818961e-08 1.0682406e-06]\n",
            " [5.0614915e-08 9.9999356e-01 3.5597575e-06 3.7548328e-10 1.3981457e-08\n",
            "  3.4351338e-11 2.1112578e-06 7.4336731e-07 1.3660417e-08 2.6968670e-09]\n",
            " [3.0189138e-13 6.0619977e-06 6.2141056e-11 3.9953414e-12 9.9999189e-01\n",
            "  1.1997615e-11 4.2069548e-10 1.8579696e-06 2.2132898e-09 1.6129769e-07]\n",
            " [4.7868188e-08 9.7036164e-08 4.3653117e-08 2.6084374e-08 9.7373663e-04\n",
            "  1.7573308e-09 3.0955212e-09 1.6873346e-06 6.5225305e-07 9.9902380e-01]\n",
            " [8.7597121e-09 9.9347053e-10 1.5368253e-09 2.9917342e-06 5.0728449e-10\n",
            "  9.9829787e-01 1.6898676e-03 2.3835151e-10 9.1932889e-06 4.1121559e-08]]\n",
            "[7 2 1 0 4 1 4 9 5]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "6m9-B2XMcb3F"
      },
      "source": [
        "Observations\n",
        "---------------------\n",
        "\n",
        "\n",
        "At the first look the results looks good. But did you also observe that we achieved the magic number as well ? If you haven't then go back and see that we achieved it in the 12th Epoch and improved over it on the 15th one . We can also try to see if more number of epochs takes it further up. But before that let's try and focus on the charts to see how it improved over different epochs and how the loss did .\n",
        "\n",
        "![image.png](attachment:image.png)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ZGkZMho3AzIQ",
        "colab": {}
      },
      "source": [
        "![image.png](attachment:image.png)\n",
        "\n",
        "\n",
        "This shows that \n",
        "\n",
        "1. The validation loss was always better than the Training loss and \n",
        "2. Simillarly the validation accuracy was always higher than the training accuracy\n",
        "3. The network also narrowed down the difference between the training and validation accuracies \n",
        "\n",
        "That means it did a great job in generalizing the data . We achieved the target with \n",
        "\n",
        "1. Less than 15000 Parameters \n",
        "2. Less than 15 epochs\n",
        "3. WIth no greater than 32 batch size\n",
        "\n",
        "\n",
        "Next Steps\n",
        "-----------------\n",
        "\n",
        "We can try the following as the next steps \n",
        "\n",
        "1. Try to achieve the magic number by improving the number of epochs without learning rate \n",
        "2. Try to get a much higher accuracy by using variable learning rate and little more epochs\n",
        "3. Analyze the effect of higher dropout percentage \n",
        "4. Analyze the effect of higher learning rate\n",
        "5. Analyze the effect of using more number of epochs ( 50 and above )\n",
        "\n",
        "\n",
        "We will try to conclude this exercise here as we met our objective . But neverthless we will try again to improve the performance by tuning the parameters . So stay tuned !\n",
        "\n",
        "\n",
        "* **************************************************************************   Prepared by Nihar Kanungo *********************************************************"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2sg33QGHvdLf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}